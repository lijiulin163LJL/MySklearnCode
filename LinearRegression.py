import numpy as npfrom .metrics import accuracy_scoreclass LogisticRegression:    def __init__(self):        self.coef_ = None        self.intercept_ = None        self._theta = None    def fit_normal(self,X_train,y_train):        """计算参数theta"""        Xb = np.hstack([np.ones((len(X_train),1)),X_train])  #计算Xb        self._theta = np.linalg.inv(Xb.T.dot(Xb)).dot(Xb.T).dot(y_train)        self.coef_ = self._theta[1:]        self.intercept_ = self._theta[0]        return self    def _sigmoid(self,t):        return 1/(1+np.exp(-t))    def fit(self,X_train,y_train,eta=0.01,n_iters=1e4):        """计算损失函数"""        def J(theta,X_b,y):            y_hat = self._sigmoid(X_b.dot(theta))            try:                return -np.sum(y*np.log(y_hat)-(1-y)*np.log(1-y_hat))/len(y)            except:                return float("inf")        def dJ(theta,X_b,y):            return X_b.T.dot(self._sigmoid(X_b.dot(theta))-y)/len(X_b)        def gradient_descent(X_b,y,inital_theta,eta,n_iters=1e4,epsilon=1e-8):            theta = inital_theta            cur_iter = 0            while cur_iter<n_iters:                dj = dJ(theta,X_b,y)                last_theta = theta                theta = theta-eta*dj                if (abs(J(theta,X_b,y)-J(last_theta,X_b,y))) < epsilon:                    break                cur_iter += 1            return theta        X_b = np.hstack([np.ones((len(X_train),1)),X_train])        initial_theta = np.zeros(X_b.shape[1])        self._theta = gradient_descent(X_b,y_train,initial_theta,eta,n_iters)        self.intercept_ = self._theta[0]        self.coef_ = self._theta[1:]        return self    def predict(self,X_test):        prob = self.predict_pro(X_test)        return np.array(prob>0.5,dtype="int")    def predict_pro(self,X_test):        Xtb = np.hstack([np.ones((len(X_test),1)),X_test])        return self._sigmoid(Xtb.dot(self._theta))    def score(self,X_test,y_test):        y_predict = self.predict(X_test)        return accuracy_score(y_test,y_predict)    def __repr__(self):        return "LogisticRegression()"